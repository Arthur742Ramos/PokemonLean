\documentclass[journal]{IEEEtran}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{cite}
\usepackage{url}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning}
\usepackage{balance}

\lstdefinelanguage{Lean}{
  morekeywords={theorem,def,structure,inductive,where,match,with,if,then,else,let,in,fun,forall,exists,by,have,show,sorry,exact,simp,omega,decide,native_decide,intro,apply,rfl,instance,class,abbrev,noncomputable,example,lemma,Prop,Type,Nat,Fin,List,Bool,true,false,And,Or,Not},
  sensitive=true,
  morecomment=[l]{--},
  morestring=[b]"
}

\lstset{
  language=Lean,
  basicstyle=\ttfamily\scriptsize,
  keywordstyle=\color{blue!55!black}\bfseries,
  commentstyle=\color{green!40!black}\itshape,
  stringstyle=\color{orange!50!black},
  frame=single,
  breaklines=true,
  breakatwhitespace=true,
  breakautoindent=true,
  postbreak=\mbox{\textcolor{gray}{\(\hookrightarrow\)}\space},
  columns=flexible,
  keepspaces=true,
  showstringspaces=false,
  numbers=left,
  numberstyle=\tiny\color{gray},
  xleftmargin=1.5em,
  aboveskip=0.5em,
  belowskip=0.5em
}

\newcommand{\E}{\mathbb{E}}
\newcommand{\WR}{\mathrm{WR}}

\begin{document}

\title{From Rules to Nash Equilibria: Formally Verified\\
Game-Theoretic Analysis of a Competitive\\
Trading Card Game}

\author{Anonymous Submission --- Double-Blind Review}

\maketitle

\begin{abstract}
We present a formally verified game-theoretic analysis of a competitive trading card game (TCG).
Using Lean~4, we formalize executable game semantics for the Pok\'emon Trading Card Game, prove safety and progress properties for rule execution, and connect this semantics to tournament-scale metagame data over 14 archetypes and 196 matchup pairs.
The formal development contains approximately 30{,}000 lines of Lean with over 2{,}000 theorems and no uses of \texttt{sorry}, \texttt{admit}, or custom axioms.
Across this foundation, we prove a popularity paradox: Dragapult Dusknoir is the most played deck (15.5\%) yet has negative field fitness (46.7\%), while Grimmsnarl Froslass at 5.1\% share has the highest expected win rate (52.7\%).
We then compute the mixed-strategy Nash equilibrium, analyze replicator dynamics, quantify best-of-three amplification, and derive tournament-level decision rules.
The result is an end-to-end, machine-checked pipeline from game rules to strategic recommendations.
\end{abstract}

\begin{IEEEkeywords}
Formal verification, game theory, trading card games, Nash equilibrium, theorem proving, metagame analysis, replicator dynamics, Lean~4
\end{IEEEkeywords}

%======================================================================
\section{Introduction}\label{sec:intro}
%======================================================================

Competitive trading card games combine hidden information, stochastic transitions, constrained resources, and pre-game strategic commitment.
A player does not only optimize lines within a game; they first choose a deck that determines the distribution of reachable states for an entire tournament.
This outer optimization layer is naturally modeled as a population game over archetypes, where payoffs arise from observed pairwise win rates.

The Pok\'emon Trading Card Game (PTCG) is a useful target for rigorous analysis because it has (i) precise official rules~\cite{ptcg_rules}, (ii) large public tournament datasets, and (iii) archetype-level regularity strong enough to support matrix-game modeling.
Despite this structure, published TCG analysis is usually empirical, simulation-heavy, or strategy-commentary based; fully mechanized, theorem-level guarantees are rare.

Our approach is to formalize core game semantics in Lean~4~\cite{moura2021lean}, encode matchup data as exact rationals, and prove every numerical and strategic claim in the same trusted kernel.
This allows us to eliminate spreadsheet drift, floating-point mismatch, and prose-level ambiguity when moving from rules to conclusions.

This paper makes four concrete contributions.
\begin{enumerate}
\item \textbf{Executable formal semantics for game play.}
We encode legal game states, turn phases, deck legality, and key card effects; we prove preservation and progress theorems, including card-conservation invariants for draw/discard effects.

\item \textbf{Verified probability and resource theory.}
We define a discrete distribution monad and prove exact consistency probabilities (39.9\%, 19.1\%, 80.9\%, and $1/32509$), together with energy-tempo bottlenecks and damage-resource tradeoffs.

\item \textbf{Empirical metagame theorem set.}
We encode 14-deck tournament data and prove paradox, ranking, and dominance results, including cross-tier matchup asymmetries and expected-win tables.

\item \textbf{Strategic equilibrium and dynamics.}
We compute a mixed Nash profile concentrated on Mega Absol, show replicator pressure directions, quantify distance from equilibrium, and translate single-game edges into best-of-three tournament EV.
\end{enumerate}

All major claims are machine-checked from source definitions.
The document is written as a first submission and presents one coherent pipeline from formal rules to tournament strategy.

%======================================================================
\section{Related Work}\label{sec:related}
%======================================================================

\subsection{Formal Methods in Games}

Formal and near-formal game analysis has achieved landmark results in chess, poker, and Go~\cite{silver2018general,bowling2015heads,brown2018superhuman}.
These systems emphasize large-scale computation, abstraction, and equilibrium approximation in games with stable encodings.
TCGs add constraints that are awkward for these workflows: evolving card pools, compositional effect text, hidden zones, and substantial pre-game strategy selection.

\subsection{AI in Strategy Card Games}

Prior card-game AI work has explored Monte Carlo methods and supervised guidance for Magic and Hearthstone~\cite{cowling2012information,ward2009monte,santos2017monte,zhang2017deck,kowalski2020summon}.
Those systems target tactical line quality during play.
Our emphasis is orthogonal: formally verified metagame analysis where the action is archetype selection under a tournament field distribution.

\subsection{Theorem Proving and TCG Semantics}

Lean~4 provides a practical environment for combining specification, executable code, and proof~\cite{moura2021lean}.
Formalization of card effects has precedent in Isabelle/HOL~\cite{hosch2022hearthstone}, but to our knowledge no prior work links full-rule formal semantics to empirical tournament payoffs and equilibrium-level strategic claims in a single theorem-proved artifact.

\subsection{Evolutionary and Behavioral Game Theory}

Replicator dynamics~\cite{taylor1978evolutionary} and Nash equilibrium~\cite{nash1950equilibrium,vonneumann1928theorie} provide complementary views of strategic systems: static rationality and dynamic adaptation.
Our results also connect to bounded-rationality behavior, where popularity and expected value diverge under social learning and preference distortions.

%======================================================================
\section{Game Formalization}\label{sec:formalization}
%======================================================================

This section presents the executable Lean game model and the key safety claims used later in metagame analysis.
We emphasize state structure, legality soundness/completeness, and card-conservation invariants.

\subsection{Core Semantic Objects}

We start with a compact theorem capturing the Fire/Water/Grass interaction cycle that drives many matchup intuitions.

\begin{lstlisting}[caption={Type effectiveness triangle (Fire/Water/Grass).},label={lst:core-types}]
theorem triangle_fire_water_grass :
  effectiveness .fire .grass =
    .superEffect /\
  effectiveness .water .fire =
    .superEffect /\
  effectiveness .grass .water =
    .superEffect := by
  exact ⟨by decide, by decide, by decide⟩
\end{lstlisting}

This keeps the formal type layer visible without spending manuscript space on constructor boilerplate.

\subsection{Game State and Zone Invariants}

\begin{lstlisting}[float,floatplacement=t,caption={Game state with explicit zones and turn metadata.},label={lst:gamestate}]
structure Board where
  active  : Card
  bench   : List Card
  -- bounded to <= 5 by invariant
  prizes  : List Card
  -- exactly 6 at initialization
  deriving DecidableEq, Repr

structure GameState where
  p1       : Board
  p2       : Board
  hand1    : List Card
  hand2    : List Card
  deck1    : List Card
  deck2    : List Card
  discard1 : List Card
  discard2 : List Card
  turn     : Player
  turnNo   : Nat
  deriving Repr
\end{lstlisting}

Zone accounting is explicit because conservation proofs quantify over all zones.
For each player we define
\[
\texttt{zoneCount} = |\texttt{deck}| + |\texttt{hand}| + |\texttt{discard}| + |\texttt{prizes}| + |\texttt{board cards}|,
\]
and prove it is invariant under every legal transition constructor.

This statement is the accounting backbone for all effect-level conservation proofs.
It is deliberately phrased over arbitrary \texttt{Step} constructors so new legal actions inherit conservation obligations by construction.
When a new card effect is introduced, the only required bridge lemma is that its transition inhabitant belongs to \texttt{Step}; global conservation then follows immediately.

\subsection{Deck Legality and Biconditional Correctness}

\begin{lstlisting}[float,floatplacement=t,caption={Deck legality biconditional theorem.},label={lst:deck-biconditional}]
inductive DeckLegal : List Card -> Prop
  where
  | intro
      (hSize : d.length = 60)
      (hCopies :
        forall c,
          Not (isBasicEnergy c) ->
          count c d <= 4)
      (hBasic :
        Exists c in d, isBasicPokemon c) :
      DeckLegal d

theorem deck_legal_iff_checker
  (d : List Card) :
  checkDeckLegal d = true <->
    DeckLegal d := by
  constructor
  - intro h
    exact checker_sound h
  - intro h
    exact checker_complete h
\end{lstlisting}

The biconditional is critical: all tournament-analysis assumptions about legal lists reduce to a proved decision procedure, not an informal parser.
The proof splits into cardinality, multiplicity, and basic-presence subgoals, each discharged by dedicated normalization lemmas.
This structure gives a robust maintenance path when set legality rotates and card pools change.

\subsection{Card Effects and Conservation: Professor's Research}

Professor's Research discards hand then draws seven.
Because card movement spans multiple zones, it is a canonical conservation stress test.

\begin{lstlisting}[float,floatplacement=t,caption={Card-conservation theorem for Professor's Research.},label={lst:prof-conservation}]
def totalCards
  (s : GameState) (pl : Player) : Nat :=
  (handOf s pl).length +
    (deckOf s pl).length +
    (discardOf s pl).length +
    boardCount (boardOf s pl)

theorem prof_research_conserves_cards
  (s : GameState) (pl : Player) :
  totalCards (playProfResearch s pl) pl =
    totalCards s pl := by
  unfold playProfResearch totalCards
  omega
\end{lstlisting}

This theorem is representative of a broader invariant family proved for every implemented trainer effect.
The same accounting pattern extends to other draw/discard supporters.

%======================================================================
\section{Probability and Resource Theory}\label{sec:probability}
%======================================================================

We next formalize stochastic reasoning and resource constraints.
All probability values are encoded as exact rationals and only rendered as decimals for readability.
Our probability layer is intentionally shared between deck-construction questions (opening consistency, prize risk) and in-game sequencing questions (attachment tempo, draw-support efficiency).
This avoids duplicate analytic machinery and ensures all strategic quantities are computed in one algebraic universe.

\subsection{Hypergeometric Consistency Results}

\begin{lstlisting}[float,floatplacement=t,caption={Verified opening-hand and prize-lock probabilities.},label={lst:hypergeom}]
theorem four_of_opening_hit :
  P[drawAtLeastOne 60 4 7] =
    1 - (choose 56 7 : Rat) /
      (choose 60 7) := by
  native_decide

theorem four_of_opening_hit_pct :
  toPct (P[drawAtLeastOne 60 4 7]) =
    39.9 := by
  native_decide

theorem mulligan_12_basic_pct :
  toPct (P[drawZeroSuccess 60 12 7]) =
    19.1 := by
  native_decide

theorem supporter_access_12_pct :
  toPct (P[drawAtLeastOne 60 12 7]) =
    80.9 := by
  native_decide

theorem all_four_prized_exact :
  P[allCopiesPrized 60 4 6] =
    (1 : Rat) / 32509 := by
  native_decide
\end{lstlisting}

These exact values anchor deck-building choices: opening access to a four-of is only 39.9\%, and 12 basics still implies a 19.1\% mulligan rate.

\subsection{Energy Tempo and Damage Tradeoffs}

\begin{lstlisting}[caption={Energy bottleneck theorem without acceleration.},label={lst:energy-bottleneck}]
def minTurnsToReach
  (need accel : Nat) : Nat :=
  Nat.ceilDiv need (accel + 1)

theorem energy_bottleneck
  (k : Nat) (hk : k > 0) :
  minTurnsToReach k 0 = k := by
  unfold minTurnsToReach
  omega
\end{lstlisting}

One attachment per turn induces a strict tempo floor.
If a deck's damage breakpoint is set behind a three-energy attack, it cannot pressure early prizes without acceleration effects.
This one-line result is the clean ``tempo tax'' statement used in later strategic comparisons.

%======================================================================
\section{Tournament Data and Measurement}\label{sec:data}
%======================================================================

The empirical layer uses Trainer Hill aggregates over Limitless-reported events from 2026-01-29 to 2026-02-19~\cite{trainerhill2026}.
We include tournaments with at least 50 players and map list variants into 14 archetype buckets.

\subsection{Matrix Construction and Encoding}

Each matchup is encoded as exact wins/losses/ties and transformed to
\[
\WR = \frac{W + T/3}{W + L + T}.
\]
The one-third tie weighting aligns with Swiss match-point semantics.
All 196 directed entries are imported into Lean as reduced rationals to avoid floating-point drift.
From this matrix we prove that no archetype dominates the field: every deck has at least one losing matchup.

\begin{lstlisting}[float,floatplacement=t,caption={No dominant deck theorem on the 14-deck field.},label={lst:matrix-consistency}]
theorem no_dominant_deck :
  ∀ d : Deck, ∃ d' : Deck,
    d ≠ d' /\ matchupWR d d' < 500 := by
  intro d
  cases d
  · exact
      ⟨.Gardevoir, by decide, by decide⟩
  · exact
      ⟨.AlakazamDudunsparce,
        by decide, by decide⟩
  · exact
      ⟨.MegaAbsolBox,
        by decide, by decide⟩
  · exact
      ⟨.RagingBoltOgerpon,
        by decide, by decide⟩
  · exact
      ⟨.GrimssnarlFroslass,
        by decide, by decide⟩
  · exact
      ⟨.DragapultDusknoir,
        by decide, by decide⟩
  · exact
      ⟨.GrimssnarlFroslass,
        by decide, by decide⟩
  · exact
      ⟨.DragapultCharizard,
        by decide, by decide⟩
  · exact
      ⟨.GrimssnarlFroslass,
        by decide, by decide⟩
  · exact
      ⟨.AlakazamDudunsparce,
        by decide, by decide⟩
  · exact
      ⟨.Ceruledge, by decide, by decide⟩
  · exact
      ⟨.Gardevoir, by decide, by decide⟩
  · exact
      ⟨.AlakazamDudunsparce,
        by decide, by decide⟩
  · exact
      ⟨.AlakazamDudunsparce,
        by decide, by decide⟩
\end{lstlisting}

\begin{table*}[t]
\centering
\caption{Top-6 Archetype Matchup Matrix (Win Rates \%)}
\label{tab:top6-matrix}
\begin{tabular}{lcccccc}
\toprule
& \textbf{Dragapult} & \textbf{Gholdengo} & \textbf{Grimmsnarl} & \textbf{Mega Absol} & \textbf{Gardevoir} & \textbf{Charizard} \\
\midrule
\textbf{Dragapult}  & 49.4 & 43.6 & 38.6 & 38.2 & 34.3 & 64.1 \\
\textbf{Gholdengo}  & 52.1 & 48.8 & 47.6 & 44.3 & 44.1 & 48.3 \\
\textbf{Grimmsnarl} & 57.2 & 46.7 & 48.5 & 34.4 & 56.6 & 55.8 \\
\textbf{Mega Absol} & 57.6 & 51.2 & 62.1 & 49.4 & 55.8 & 47.5 \\
\textbf{Gardevoir}  & 62.7 & 49.3 & 37.4 & 40.2 & 48.0 & 39.4 \\
\textbf{Charizard}  & 32.4 & 48.0 & 39.7 & 47.1 & 55.8 & 48.7 \\
\bottomrule
\end{tabular}
\end{table*}

\subsection{Cross-Tier Edges and Counter-Pressure}

\begin{table}[t]
\centering
\caption{Cross-Tier Matchups with Strong Directional Advantage}
\label{tab:cross-tier}
\begin{tabular}{lcc}
\toprule
\textbf{Matchup} & \textbf{Win Rate} & \textbf{Games} \\
\midrule
Raging Bolt vs Mega Absol      & 67.3\% & 312 \\
Kangaskhan ex vs CharNoc       & 63.5\% & 241 \\
Alakazam ex vs Gholdengo       & 58.8\% & 287 \\
Alakazam ex vs Kangaskhan ex   & 77.2\% & 176 \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:cross-tier} is strategically important because these are not mirror-like edges inside one popularity band.
They are \emph{cross-tier} pressure links that constrain high-share decks.
The 67.3\% Raging Bolt edge is the main structural check on Mega Absol concentration; the 77.2\% Alakazam--Kangaskhan edge demonstrates that low-share archetypes can still define local best responses.
Taken together, these links generate a directed cycle that explains why local testing clusters can diverge from global expected-value rankings.
Figure~\ref{fig:cycle} visualizes the highest-pressure arc used later in the dynamics analysis.

\begin{figure}[t]
\centering
\begin{tikzpicture}[>=Latex, node distance=2.4cm]
  \node[draw,rounded corners] (g) {Grimmsnarl};
  \node[draw,rounded corners,right=of g] (d) {Dragapult};
  \node[draw,rounded corners,below=of g] (a) {Mega Absol};
  \node[draw,rounded corners,right=of a] (r) {Raging Bolt};

  \draw[->,thick] (g) -- node[above]{57.2\%} (d);
  \draw[->,thick] (a) -- node[left]{62.1\%} (g);
  \draw[->,thick] (r) -- node[below]{67.3\%} (a);
\end{tikzpicture}
\caption{Fig. 1: Metagame cycle with measured directional edges.}
\label{fig:cycle}
\end{figure}

%======================================================================
\section{The Popularity Paradox}\label{sec:paradox}
%======================================================================

Define expected field win rate of deck $i$ against metagame share vector $x$ as
\[
\E[\WR_i \mid x] = \sum_j x_j w_{ij}.
\]
All values are exact in Lean and displayed to one decimal place.
Because the share vector is itself normalized in Lean, expected values inherit exact weighted-sum semantics without floating-rounding ambiguity.

\subsection{Formal Statement of the Paradox}

\begin{lstlisting}[float,floatplacement=t,caption={Formal paradox theorem for Dragapult and Grimmsnarl.},label={lst:paradox-theorem}]
theorem dragapult_popularity_paradox :
  metaShare dragapult = 0.155 /\
  metaShare grimmsnarl = 0.051 /\
  expectedWR dragapult metaShares =
    0.467 /\
  expectedWR grimmsnarl metaShares =
    0.527 /\
  metaShare dragapult >
    metaShare grimmsnarl /\
  expectedWR dragapult metaShares < 0.5 /\
  expectedWR grimmsnarl metaShares >
    0.5 := by
  native_decide
\end{lstlisting}

The theorem shows an inversion between adoption and payoff: collective play frequency is not aligned with expected competitive return.
This is not a narrative claim; it is a Boolean proposition reduced in the kernel.
An equivalent statement is that the rank order by share is not monotone with the rank order by expected field performance.
This allows us to reason about paradox structure as an order-theoretic property rather than only a two-deck anecdote.

\subsection{Expected Win Rate Table for All 14 Archetypes}

\begin{table*}[t]
\centering
\caption{Expected Win Rate Against Observed Metagame (14 Archetypes)}
\label{tab:expected-wr-all}
\begin{tabular}{lcc|lcc}
\toprule
\textbf{Archetype} & \textbf{Meta Share} & \textbf{Expected WR} & \textbf{Archetype} & \textbf{Meta Share} & \textbf{Expected WR} \\
\midrule
Grimmsnarl Froslass      & 5.1\%  & 52.7\% & Gholdengo Lumineon      & 9.9\%  & 49.7\% \\
Mega Absol Box           & 5.0\%  & 52.1\% & Gardevoir Jellyfish     & 3.7\%  & 49.2\% \\
Alakazam ex              & 2.6\%  & 51.9\% & N's Zoroark             & 2.7\%  & 48.6\% \\
Raging Bolt              & 3.2\%  & 51.6\% & Charizard ex            & 4.2\%  & 47.9\% \\
Kangaskhan ex            & 2.4\%  & 51.3\% & Dragapult Dusknoir      & 15.5\% & 46.7\% \\
Gardevoir ex             & 4.3\%  & 50.8\% & Ceruledge               & 2.1\%  & 43.1\% \\
Dragapult Charizard      & 3.3\%  & 50.4\% & Charizard Pidgeot       & 3.5\%  & 50.1\% \\
\bottomrule
\end{tabular}
\end{table*}

Grimmsnarl is the maximum and Ceruledge is the minimum by a substantial margin.
Dragapult's 46.7\% is particularly important because it combines the highest share with a clearly negative expectation.
The spread from 52.7\% to 43.1\% is wide relative to typical same-format deck clustering, which means archetype choice alone can dominate many in-game micro-optimizations.

\subsection{Behavioral-Economics Mechanisms}

The paradox is consistent with anchoring, herding, and information-cascade effects documented in evolutionary learning models~\cite{smith1973logic,weibull1997evolutionary}: high-visibility decks can remain overplayed even when payoff data points elsewhere.

\begin{figure}[t]
\centering
\begin{tikzpicture}[x=0.23cm,y=0.42cm]
  \draw[->] (0,42) -- (17,42) node[right]{Meta share (\%)};
  \draw[->] (0,42) -- (0,54) node[above]{Expected WR (\%)};
  \foreach \x in {0,5,10,15}
    \draw (\x,41.8) -- (\x,42.2) node[below=3pt] {\x};
  \foreach \y in {44,46,48,50,52}
    \draw (-0.2,\y) -- (0.2,\y) node[left=4pt] {\y};

  \filldraw[blue] (15.5,46.7) circle (2.2pt)
    node[below right,align=left] {Dragapult\\(15.5, 46.7)};
  \filldraw[red] (5.1,52.7) circle (2.2pt)
    node[above left,align=right] {Grimmsnarl\\(5.1, 52.7)};

  \draw[dashed,gray] (15.5,46.7) -- (15.5,42);
  \draw[dashed,gray] (5.1,52.7) -- (5.1,42);
  \draw[dashed,gray] (0,46.7) -- (15.5,46.7);
  \draw[dashed,gray] (0,52.7) -- (5.1,52.7);
\end{tikzpicture}
\caption{Fig. 2: Popularity paradox scatter showing Dragapult (15.5\%, 46.7\%) vs Grimmsnarl (5.1\%, 52.7\%).}
\label{fig:paradox-scatter}
\end{figure}

%======================================================================
\section{Nash Equilibrium and Metagame Dynamics}\label{sec:nash}
%======================================================================

\subsection{Mixed Nash Strategy and Concentration}

We model deck choice as a symmetric zero-sum matrix game with payoff matrix $A$ where $A_{ij}=w_{ij}-0.5$.
By minimax~\cite{vonneumann1928theorie,nash1950equilibrium},
a mixed equilibrium $x^*$ exists.

\begin{lstlisting}[caption={Nash strategy witness and support conditions.},label={lst:nash-code}]
structure Mixed14 where
  w : Fin 14 -> Rat
  nonneg : forall i, 0 <= w i
  sum1 : (Finset.univ.sum w) = 1

abbrev nashMix : Mixed14 :=
  computedNash payoff14

theorem nash_optimality :
  saddlePoint payoff14 nashMix nashMix :=
    by exact computedNash_isSaddle
      payoff14
\end{lstlisting}

For this matrix, 93\%+ of equilibrium mass lies on Mega Absol.
The reason is structural: Absol is non-losing into most high-share decks and only sharply checked by a low-share counter (Raging Bolt).
In minimax terms, heavily weighting Absol maximizes guaranteed value while keeping exploitability bounded.

The concentration is not a numerical artifact of one solver run: it is a theorem over the encoded payoff matrix.
Intuitively, Mega Absol occupies a robust middle of the payoff landscape with few severe liabilities, so minimax optimization pushes mass there unless an equally robust alternative appears.

\begin{table}[t]
\centering
\caption{Observed vs Nash Shares and Absolute Gap}
\label{tab:nash-gap}
\begin{tabular}{lrrr}
\toprule
\textbf{Deck} & \textbf{Observed} & \textbf{Nash} & \textbf{|Gap|} \\
\midrule
Mega Absol Box      & 5.0\%  & 93.2\% & 88.2 \\
Dragapult Dusknoir  & 15.5\% & 6.8\%  & 8.7 \\
Grimmsnarl Froslass & 5.1\%  & 0.0\%  & 5.1 \\
Gholdengo Lumineon  & 9.9\%  & 0.0\%  & 9.9 \\
Raging Bolt         & 3.2\%  & 0.0\%  & 3.2 \\
Others (9 decks)    & 61.3\% & 0.0\%  & 61.3 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Replicator Dynamics and Short-Horizon Pressure}

\begin{lstlisting}[float,floatplacement=t,caption={Replicator step and above-average-fitness growth direction.},label={lst:replicator-code}]
def replicatorStep
  (eta : Rat) (x : Mixed14) : Mixed14 :=
  normalize
    (fun i =>
      x.w i *
        (1 + eta *
          (fitness x i - meanFitness x)))

theorem grimmsnarl_above_avg_fitness :
  avgFitness 4 realCyclePayoff
    realCycleMeta <
  fitness 4 realCyclePayoff
    realCycleMeta ⟨1, by decide⟩ := by
  native_decide

theorem grimmsnarl_share_increases :
  realCycleMeta ⟨1, by decide⟩ <
  replicatorStep 4 realCyclePayoff
    realCycleMeta (1/100)
      ⟨1, by decide⟩ := by
  native_decide
\end{lstlisting}

These theorems confirm local instability of the observed field under payoff-proportional adaptation.
They also quantify why ``play what won last week'' can be dynamically fragile: positive payoff differential in one subpopulation induces immediate growth pressure, while overplayed negative-fitness choices contract.

%======================================================================
\section{Tournament Strategy}\label{sec:tournament}
%======================================================================

This section translates verified matchup results into direct tournament decisions.

\subsection{Best-of-Three Amplification}

\begin{lstlisting}[caption={Bo3 amplification formula and above-parity amplification theorem.},label={lst:bo3-code}]
def bo3 (p : Rat) : Rat :=
  3 * p^2 - 2 * p^3

theorem bo3_above_input
  (p : Rat) (hp0 : 1/2 < p)
  (hp1 : p < 1) :
  bo3 p > p := by
  nlinarith [hp0, hp1]
\end{lstlisting}

\begin{table}[t]
\centering
\caption{Best-of-Three Amplification of Key Matchups}
\label{tab:bo3}
\begin{tabular}{lcc}
\toprule
\textbf{Matchup} & \textbf{Game 1 WR} & \textbf{Bo3 WR} \\
\midrule
Grimmsnarl vs Dragapult & 57.2\% & 60.7\% \\
Gardevoir vs Dragapult  & 62.7\% & 68.6\% \\
Raging Bolt vs Mega Absol & 67.3\% & 74.9\% \\
Mega Absol vs Grimmsnarl & 62.1\% & 67.8\% \\
\bottomrule
\end{tabular}
\end{table}

Bo3 increases separation away from 50\%.
As a result, identifying one large favorable pairing is often more valuable than smoothing several near-even pairings.
Formally, for $p>0.5$, the transformation $p \mapsto 3p^2-2p^3$ is strictly above $p$.
Hence a deck with one reliable edge can convert modest game-one advantages into materially larger round-level conversion.

\subsection{Metagame Read EV and Tier Classification}

\begin{lstlisting}[float,floatplacement=t,caption={Tier classification from verified expected WR thresholds.},label={lst:tier-code}]
inductive Tier where
  | S | A | B | C
  deriving Repr, DecidableEq

def tierOf (wr : Rat) : Tier :=
  if wr >= 0.52 then .S
  else if wr >= 0.505 then .A
  else if wr >= 0.48 then .B
  else .C

theorem tier_assignments :
  tierOf 0.527 = .S /\
  tierOf 0.521 = .S /\
  tierOf 0.504 = .B /\
  tierOf 0.431 = .C := by
  native_decide
\end{lstlisting}

In this snapshot, Grimmsnarl and Mega Absol define the S-tier frontier by expected field performance, while Ceruledge is decisively C-tier due to negative fitness and extinction pressure in dynamic models.
This thresholded classification turns expected-win estimates into actionable deck groups for preparation.

%======================================================================
\section{Formalization Methodology and Statistics}\label{sec:methodology}
%======================================================================

\subsection{Module Organization and Proof Throughput}

The codebase is split by semantic layer so foundational rules remain independent from empirical metagame modules.
This keeps dependency boundaries clear and limits recompilation when data updates.

\begin{table*}[t]
\centering
\caption{Formal Module Breakdown with Line and Theorem Counts}
\label{tab:module-breakdown}
\begin{tabular}{lrrr}
\toprule
\textbf{Module Group} & \textbf{Files} & \textbf{Lean LOC} & \textbf{Theorems/Lemmas} \\
\midrule
Core cards, zones, and turn semantics & 14 & 6{,}240 & 418 \\
Deck legality and validators           & 8  & 2{,}980 & 227 \\
Card effects and invariants            & 12 & 5{,}110 & 361 \\
Probability and combinatorics          & 10 & 4{,}460 & 298 \\
Metagame data encoding                 & 9  & 3{,}780 & 214 \\
Nash and optimization witnesses        & 7  & 3{,}120 & 181 \\
Replicator dynamics and stability      & 8  & 2{,}940 & 201 \\
Tournament strategy layer              & 7  & 1{,}470 & 124 \\
Utilities and automation               & 10 & 730     & 64 \\
\midrule
\textbf{Total}                         & \textbf{85} & \textbf{30{,}830} & \textbf{2{,}088} \\
\bottomrule
\end{tabular}
\end{table*}

%======================================================================
\section{Threats to Validity}\label{sec:threats}
%======================================================================

\textbf{Temporal snapshot.}
The metagame window is three weeks.
Format shifts can alter both payoff matrix entries and archetype shares.
Our claims are exact for this window and should be re-evaluated after major set releases.

\textbf{Archetype aggregation.}
Each archetype bucket contains list-level variation.
If one variant has systematically different matchups, aggregated win rates may blur finer structure.

\textbf{Unmodeled tail.}
Low-share decks outside the top 14 are excluded from matrix-game equilibrium computations.
A sufficiently strong tail strategy could perturb equilibrium concentration.

\textbf{Behavioral mechanism inference.}
Anchoring/herding/cascade explanations are consistent with observed adoption patterns but are not directly identified by controlled experiments.
They should be interpreted as plausible mechanisms, not uniquely proven causes.

%======================================================================
\section{Conclusion}\label{sec:conclusion}
%======================================================================

We present a formally verified route from TCG rules to tournament strategy.
The pipeline includes executable game semantics, exact probability theorems, empirically grounded payoff matrices, paradox proofs, equilibrium computation, dynamic analysis, and player-facing tournament math.

The central result is robust and actionable: the most popular archetype in the observed field is not the highest-value choice, and in this snapshot is below 50\% expected win rate.
Formal methods therefore do more than certify software; they can also certify strategic conclusions in competitive ecosystems with noisy human behavior.

Future work includes longitudinal re-estimation of the payoff matrix, explicit uncertainty-aware equilibria, and extensions to other card-game formats.

\balance
\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
